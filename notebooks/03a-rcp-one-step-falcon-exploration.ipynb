{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"tiiuae/falcon-rw-1b\"\n",
    "dataset_name=\"yelp_review_full\"\n",
    "accelerator = Accelerator()\n",
    "max_input_seq_length = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.  Just load the train split.  Different datasets have different splits, but\n",
    "# having a train split is common.\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to use a small subset of the dataset for this example.\n",
    "# Note that dataset[:1000] would seem to work, but it doesn't.  In particular,\n",
    "# dataset[:1000] is not a dataset object, but a dictionary.  So, we use the\n",
    "# select method to get a dataset object.\n",
    "dataset = dataset.shuffle(42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0854944d19a242eabbefcc26974fd840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This converts the dataset to a format that the model can understand.\n",
    "# In particlar, it takes the words and converts them to numbers/tokens.\n",
    "# Note, the pdding side is left since that is that the CausalLM model expects.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "# NOTE: the tokenizer.pad_token is a special token that is used to pad sequences to the same length.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# NOT TESTED: I think this gets a batch of samples as defined by the map function.\n",
    "# So, the longest refers to the longest sequence in the batch.\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding='longest', truncation=True, max_length=max_input_seq_length)\n",
    "\n",
    "# NOTE: the map function does some fancy caching.  I.e., the first time you run it, it will\n",
    "# take a while.  But, the second time you run it, it will be much faster.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "# We don't need the labels anymore, so we remove them.\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"label\", \"text\"])\n",
    "# From https://huggingface.co/docs/datasets/v2.15.0/en/package_reference/main_classes#datasets.Dataset.set_format\n",
    "#     Set __getitem__ return format using this transform. The transform is applied on-the-fly on batches when __getitem__ is called. \n",
    "#     type (str, optional) â€” Either output type selected in [None, 'numpy', 'torch', 'tensorflow', 'pandas', 'arrow', 'jax']. None means __getitem__ returns python objects (default).\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_datasets, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example text\n",
      "{'label': 4, 'text': \"I stalk this truck.  I've been to industrial parks where I pretend to be a tech worker standing in line, strip mall parking lots, and of course the farmer's market.  The bowls are so so absolutely divine.  The owner is super friendly and he makes each bowl by hand with an incredible amount of pride.  You gotta eat here guys!!!\"}\n",
      "example tokenized text\n",
      "{'input_ids': tensor([   40, 31297,   428,  7779,    13,   220,   314,  1053,   587,   284,\n",
      "         7593, 14860,   810,   314, 16614,   284,   307]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "example decoded tokenized text\n",
      "I stalk this truck.  I've been to industrial parks where I pretend to be\n"
     ]
    }
   ],
   "source": [
    "# A little sanity check.\n",
    "print('example text')\n",
    "print(dataset[0])\n",
    "print('example tokenized text')\n",
    "print(tokenized_datasets[0])\n",
    "print('example decoded tokenized text')\n",
    "print(tokenizer.decode(tokenized_datasets[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spy(torch.nn.Module):\n",
    "        def __init__(self, model, debug=False):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.debug = debug\n",
    "            self.inputs = []\n",
    "            self.outputs = []\n",
    "            self.last_size = 0\n",
    "\n",
    "        def forward(self, *args, **kwargs):\n",
    "            self.inputs.append(args)\n",
    "            output = self.model(*args, **kwargs)\n",
    "            self.outputs.append(output)\n",
    "            if self.debug:\n",
    "                print(f'args {args}')\n",
    "                print(f'kwargs {kwargs}')\n",
    "                print(f'output {output}')\n",
    "            return output\n",
    "\n",
    "        def print_last_input(self):\n",
    "            \"\"\"prints the shapes of all the inputs that have not been printed yet\n",
    "            \"\"\"\n",
    "            print(f'{self.last_size} {len(self.inputs)}')\n",
    "            for i in range(self.last_size, len(self.inputs)):\n",
    "                print(f'{i} {self.inputs[i][0].shape}')\n",
    "            self.last_size = len(self.inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalconForCausalLM(\n",
      "  (transformer): FalconModel(\n",
      "    (word_embeddings): Embedding(50304, 2048)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x FalconDecoderLayer(\n",
      "        (self_attention): FalconAttention(\n",
      "          (query_key_value): FalconLinear(in_features=2048, out_features=6144, bias=True)\n",
      "          (dense): FalconLinear(in_features=2048, out_features=2048, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): FalconMLP(\n",
      "          (dense_h_to_4h): FalconLinear(in_features=2048, out_features=8192, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (dense_4h_to_h): FalconLinear(in_features=8192, out_features=2048, bias=True)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a spy to the embedding layer.\n",
    "embedding_spy = Spy(model.transformer.word_embeddings)\n",
    "model.transformer.word_embeddings = embedding_spy\n",
    "\n",
    "# Add a spy to each of the transformer layers.\n",
    "transformer_layer_spies = []\n",
    "for i, layer in enumerate(model.transformer.h):\n",
    "    transformer_layer_spies.append(Spy(layer))\n",
    "    model.transformer.h[i] = transformer_layer_spies[i]\n",
    "\n",
    "# Add a spy to the final layer norm.\n",
    "layer_norm_spy = Spy(model.transformer.ln_f)\n",
    "model.transformer.ln_f = layer_norm_spy\n",
    "\n",
    "# Add a spy to the output layer.\n",
    "output_spy = Spy(model.lm_head)\n",
    "model.lm_head = output_spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1212,  318,  257, 2423,  286,  257, 7072,   13,  220,  383, 2057,  373]])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"This is a review of a restaurant.  The food was\"\n",
    "input = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = accelerator.prepare(model)\n",
    "# Note, the accelerator is cool, but only handles dataloaders.  So, for this example, we need to do it ourselves.\n",
    "input = input.to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready for the most simple exampl of running the model.\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[1212,  318,  257, 2423,  286,  257, 7072,   13,  220,  383, 2057,  373]],\n",
       "         device='cuda:0'),)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_spy.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.0102,  0.0081, -0.0007,  ..., -0.0074,  0.0126, -0.0124],\n",
       "          [ 0.0084,  0.0072,  0.0198,  ..., -0.0066, -0.0183,  0.0156],\n",
       "          [-0.0005, -0.0045,  0.0157,  ...,  0.0152, -0.0175, -0.0374],\n",
       "          ...,\n",
       "          [ 0.0065,  0.0034,  0.0212,  ...,  0.0381,  0.0072, -0.0047],\n",
       "          [-0.0339, -0.0381,  0.0215,  ...,  0.0017, -0.0064,  0.0088],\n",
       "          [ 0.0311,  0.0049,  0.0199,  ..., -0.0162,  0.0062,  0.0064]]],\n",
       "        device='cuda:0', grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding_spy.outputs[0].shape)\n",
    "embedding_spy.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0102,  0.0081, -0.0007,  ..., -0.0074,  0.0126, -0.0124],\n",
       "         [ 0.0084,  0.0072,  0.0198,  ..., -0.0066, -0.0183,  0.0156],\n",
       "         [-0.0005, -0.0045,  0.0157,  ...,  0.0152, -0.0175, -0.0374],\n",
       "         ...,\n",
       "         [ 0.0065,  0.0034,  0.0212,  ...,  0.0381,  0.0072, -0.0047],\n",
       "         [-0.0339, -0.0381,  0.0215,  ...,  0.0017, -0.0064,  0.0088],\n",
       "         [ 0.0311,  0.0049,  0.0199,  ..., -0.0162,  0.0062,  0.0064]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer_spies[0].inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5418, -0.0461,  0.2198,  ...,  0.0378,  0.3550, -0.3398],\n",
       "         [-0.3592,  0.0346,  0.0228,  ..., -0.0202, -0.0376, -0.1926],\n",
       "         [-0.0531,  0.0472, -0.0923,  ...,  0.0454,  0.2463, -0.0051],\n",
       "         ...,\n",
       "         [ 0.0854,  0.0670,  0.0658,  ...,  0.1739, -0.0161, -0.1793],\n",
       "         [-0.1771, -0.1400,  0.3323,  ...,  0.4190, -0.2321,  0.0036],\n",
       "         [-0.1761,  0.0589, -0.1985,  ...,  0.0311,  0.0280,  0.0314]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer_spies[0].outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5418, -0.0461,  0.2198,  ...,  0.0378,  0.3550, -0.3398],\n",
       "         [-0.3592,  0.0346,  0.0228,  ..., -0.0202, -0.0376, -0.1926],\n",
       "         [-0.0531,  0.0472, -0.0923,  ...,  0.0454,  0.2463, -0.0051],\n",
       "         ...,\n",
       "         [ 0.0854,  0.0670,  0.0658,  ...,  0.1739, -0.0161, -0.1793],\n",
       "         [-0.1771, -0.1400,  0.3323,  ...,  0.4190, -0.2321,  0.0036],\n",
       "         [-0.1761,  0.0589, -0.1985,  ...,  0.0311,  0.0280,  0.0314]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer_spies[1].inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5607,  3.2704,  1.5336,  ...,  0.1166,  0.9541, -3.9348],\n",
       "         [ 1.3911,  0.5455,  3.2251,  ...,  1.8272,  1.5874, -2.5345],\n",
       "         [ 0.3320, -0.5699,  2.4946,  ...,  1.6166,  1.9061,  0.1447],\n",
       "         ...,\n",
       "         [-0.3299, -0.7877,  2.4874,  ...,  1.0747, -0.7235,  1.0040],\n",
       "         [ 1.5230,  0.3460,  4.8440,  ...,  1.5909,  0.9555,  0.8341],\n",
       "         [-1.7289, -1.2445,  2.1949,  ...,  1.5398,  1.5457,  0.0147]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer_spies[22].outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5607,  3.2704,  1.5336,  ...,  0.1166,  0.9541, -3.9348],\n",
       "         [ 1.3911,  0.5455,  3.2251,  ...,  1.8272,  1.5874, -2.5345],\n",
       "         [ 0.3320, -0.5699,  2.4946,  ...,  1.6166,  1.9061,  0.1447],\n",
       "         ...,\n",
       "         [-0.3299, -0.7877,  2.4874,  ...,  1.0747, -0.7235,  1.0040],\n",
       "         [ 1.5230,  0.3460,  4.8440,  ...,  1.5909,  0.9555,  0.8341],\n",
       "         [-1.7289, -1.2445,  2.1949,  ...,  1.5398,  1.5457,  0.0147]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer_spies[23].inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9322,  1.7793,  2.3793,  ...,  1.7575,  0.6972, -0.0619],\n",
       "         [ 2.3636,  2.3833,  5.2714,  ...,  4.1948, -1.3329, -5.2314],\n",
       "         [ 1.7173,  0.3608,  4.3707,  ...,  3.4157, -0.2490, -2.8648],\n",
       "         ...,\n",
       "         [ 2.2031,  1.2303,  4.7532,  ...,  3.7923, -3.5564, -1.9627],\n",
       "         [ 2.9893,  2.0272,  6.1852,  ...,  3.1881, -1.5452, -1.3266],\n",
       "         [-0.4662,  0.7712,  4.5110,  ...,  3.3452, -0.3409, -2.7155]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer_spies[23].outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9322,  1.7793,  2.3793,  ...,  1.7575,  0.6972, -0.0619],\n",
       "         [ 2.3636,  2.3833,  5.2714,  ...,  4.1948, -1.3329, -5.2314],\n",
       "         [ 1.7173,  0.3608,  4.3707,  ...,  3.4157, -0.2490, -2.8648],\n",
       "         ...,\n",
       "         [ 2.2031,  1.2303,  4.7532,  ...,  3.7923, -3.5564, -1.9627],\n",
       "         [ 2.9893,  2.0272,  6.1852,  ...,  3.1881, -1.5452, -1.3266],\n",
       "         [-0.4662,  0.7712,  4.5110,  ...,  3.3452, -0.3409, -2.7155]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm_spy.inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6132,  1.4738,  3.1858,  ...,  1.3919, -1.6163, -3.5076],\n",
       "        [ 1.2990,  1.5379,  4.2701,  ...,  3.0219, -2.1128, -5.5462],\n",
       "        [ 0.9190, -0.1588,  3.9960,  ...,  2.7389, -1.2626, -3.8932],\n",
       "        ...,\n",
       "        [ 0.9481,  0.4120,  3.4575,  ...,  2.3792, -3.9171, -2.6639],\n",
       "        [ 2.1224,  1.4004,  5.8361,  ...,  2.5096, -2.6661, -2.4685],\n",
       "        [-1.0004,  0.2386,  3.6133,  ...,  2.3228, -1.1924, -3.2386]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm_spy.outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6132,  1.4738,  3.1858,  ...,  1.3919, -1.6163, -3.5076],\n",
       "         [ 1.2990,  1.5379,  4.2701,  ...,  3.0219, -2.1128, -5.5462],\n",
       "         [ 0.9190, -0.1588,  3.9960,  ...,  2.7389, -1.2626, -3.8932],\n",
       "         ...,\n",
       "         [ 0.9481,  0.4120,  3.4575,  ...,  2.3792, -3.9171, -2.6639],\n",
       "         [ 2.1224,  1.4004,  5.8361,  ...,  2.5096, -2.6661, -2.4685],\n",
       "         [-1.0004,  0.2386,  3.6133,  ...,  2.3228, -1.1924, -3.2386]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_spy.inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 50304])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_spy.outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a review of a restaurant.  The food was\n",
      "0 318  is\n",
      "1 257  a\n",
      "2 24659  continuation\n",
      "3 286  of\n",
      "4 262  the\n",
      "5 1492  book\n",
      "6 326  that\n",
      "7 198 \n",
      "\n",
      "8 198 \n",
      "\n",
      "9 2057  food\n",
      "10 373  was\n",
      "11 922  good\n"
     ]
    }
   ],
   "source": [
    "print(prompt)\n",
    "logits = output_spy.outputs[0]\n",
    "\n",
    "for i in range(logits.shape[1]):\n",
    "    highest = torch.argmax(output_spy.outputs[0][0, i, :])\n",
    "    print(f'{i} {highest} {tokenizer.decode([highest])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' good'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
